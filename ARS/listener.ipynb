{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e245e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hair': [90, 0, 150, 20], 'cap': [90, 0, 150, 20], 'face': [80, 10, 150, 55], 'neck': [100, 30, 150, 70], 'coat': [20, 40, 200, 110], 'belt': [60, 80, 180, 140], 'pants': [50, 120, 190, 210], 'shoes': [20, 200, 200, 240]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def encode_image(img , transform):\n",
    "    input_tensor = transform(img)\n",
    "    input_tensor = input_tensor.half()\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    output_tensor = pipe.vae.encode(input_tensor)\n",
    "    return output_tensor.latent_dist.sample()[0]\n",
    "\n",
    "\n",
    "\n",
    "def encode_image_avator(img , transform):\n",
    "    transformed_image = transform(Image.fromarray(np.array(img)[:, :, :3]))\n",
    "    pil_transformed_image = transforms.ToPILImage()(transformed_image)\n",
    "    return encode_image(pil_transformed_image, transform)\n",
    "\n",
    "def calculate_mse(tensor1, tensor2):\n",
    "    return torch.mean((tensor1 - tensor2) ** 2)\n",
    "\n",
    "def calculate_pearson_similarity(tensor1, tensor2):\n",
    "    mean_tensor1 = torch.mean(tensor1)\n",
    "    mean_tensor2 = torch.mean(tensor2)\n",
    "    centered_tensor1 = tensor1 - mean_tensor1\n",
    "    centered_tensor2 = tensor2 - mean_tensor2\n",
    "    dot_product = torch.sum(centered_tensor1 * centered_tensor2)\n",
    "    norm_tensor1 = torch.norm(centered_tensor1)\n",
    "    norm_tensor2 = torch.norm(centered_tensor2)\n",
    "    similarity = dot_product / (norm_tensor1 * norm_tensor2)\n",
    "    return similarity\n",
    "\n",
    "def calculate_cosine_similarity(tensor1, tensor2):\n",
    "    dot_product = torch.sum(tensor1 * tensor2)\n",
    "    norm_tensor1 = torch.norm(tensor1)\n",
    "    norm_tensor2 = torch.norm(tensor2)\n",
    "    similarity = dot_product / (norm_tensor1 * norm_tensor2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "avator_path = './data/avator/PRIEST'\n",
    "file_list = os.listdir(avator_path)\n",
    "folder_list = [item for item in file_list if not '.' in item]\n",
    "\n",
    "belt_bb = [60, 80, 180, 140]\n",
    "pants_bb = [50, 120, 190, 210]\n",
    "shoes_bb = [20, 200, 200, 240]\n",
    "face_bb = [80, 10, 150, 55]\n",
    "neck_bb = [100, 30, 150, 70]\n",
    "cap_bb = [90, 0, 150, 20]\n",
    "coat_bb = [20, 40, 200, 110]\n",
    "coat_bb = [20, 40, 200, 110]\n",
    "hair_bb = [90, 0, 150, 20]\n",
    "\n",
    "bb_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "folder_list = ['hair' , 'cap' , 'face' , 'neck' , 'coat' , 'belt' , 'pants' , 'shoes']\n",
    "position_list = [item + ' position' for item in folder_list]\n",
    "avator_path = './data/avator/PRIEST'\n",
    "\n",
    "        \n",
    "for part, bb in zip(folder_list, [hair_bb, cap_bb, face_bb, neck_bb, coat_bb, belt_bb, pants_bb, shoes_bb]):\n",
    "    bb_dict[part] = bb\n",
    "\n",
    "print(bb_dict)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize the image to a desired size\n",
    "    transforms.ToTensor(),       # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd58ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "class ImageHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if not event.is_directory and event.src_path.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            print(\"New image file created:\", event.src_path)\n",
    "            pil_image = Image.open(event.src_path)\n",
    "            prompt = \"a men wearing game costume\"\n",
    "\n",
    "            target_size = (244, 244)  # Set your desired size\n",
    "            resized_image = pil_image.resize(target_size)\n",
    "            \n",
    "            #images = pipe(prompt=prompt,  image=resized_image, num_inference_steps = 150).images[0]\n",
    "            images = pipe(prompt=prompt, image=resized_image, guidance_scale=1, strength=0.25).images[0]\n",
    "            print(\"Generate image\")\n",
    "            plt.imshow(images)\n",
    "                        \n",
    "            recommed_dict = {}\n",
    "\n",
    "            for part in bb_dict:\n",
    "                part_img = images.crop((bb_dict[part][0], bb_dict[part][1], bb_dict[part][2], bb_dict[part][3]))\n",
    "                image_lv = encode_image(part_img , transform)\n",
    "\n",
    "                part_latents = []\n",
    "                part_avators = []\n",
    "                folder_list = ['hair' , 'cap' , 'face' , 'neck' , 'coat' , 'belt' , 'pants' , 'shoes']\n",
    "                avator_path = './data/avator/PRIEST'\n",
    "\n",
    "                full_paths = os.path.join(avator_path, part)\n",
    "                part_imgs = natsorted(os.listdir(full_paths))\n",
    "                part_imgs = [file for file in part_imgs if file.lower().endswith('.png')]\n",
    "                for path in tqdm(part_imgs , desc = f'{part}'):\n",
    "                    \n",
    "                    part_img_path = os.path.join(f'./data/avator/PRIEST/{part}' , path)\n",
    "                    #print(part_img_path)\n",
    "                    avator_part = Image.open(part_img_path)\n",
    "                    avator_part = cv2.cvtColor(np.array(avator_part), cv2.COLOR_BGR2RGB)\n",
    "                    part_latents.append(encode_image_avator(avator_part, transform))\n",
    "                    part_avators.append(avator_part)\n",
    "                    \n",
    "                mse_list = [calculate_mse(image_lv, t).item() for t in part_latents]\n",
    "                part_rec_mse = np.array(mse_list).argmin()\n",
    "                plt.imshow(part_avators[part_rec_mse])\n",
    "                recommed_dict[part+' position'] = str(part_rec_mse*28)\n",
    "            \n",
    "            json_data = json.dumps([recommed_dict])\n",
    "            save_name = event.src_path.split('/')[-1]\n",
    "            print(save_name)\n",
    "\n",
    "            with open(f'./{output_dir}/{save_name}.json', 'w') as file:\n",
    "                file.write(json_data)\n",
    "\n",
    "\n",
    "            print('create json')\n",
    "            print(f'create json name : ')\n",
    "            with open(f'./{output_dir}/{save_name}.json', 'rb') as f:\n",
    "                string_param = save_name.split('.')[0] +\".\"+ save_name.split('.')[1]\n",
    "                files = {'file': f }\n",
    "                data = {'userid': string_param}\n",
    "\n",
    "                response = requests.post(post_url, data=data, files=files)\n",
    "            print('Response status code:', response.status_code)\n",
    "            # Print more detailed response information\n",
    "            print('Response headers:', response.headers)\n",
    "            print('Response body:', response.text)\n",
    "\n",
    "            # If the response is in JSON format, you can use response.json() to parse it\n",
    "            try:\n",
    "                print('Parsed JSON response:', response.json())\n",
    "            except Exception as e:\n",
    "                print('Could not parse response as JSON. Exception:', str(e))\n",
    "\n",
    "            os.remove(event.src_path)\n",
    "            os.remove(f'./{output_dir}/{save_name}.json')\n",
    "            print('Image file deleted:', event.src_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f1ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "New image file created: input_image/zeskywa499@gmail.com.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd9198660034c9397093aee9c47bd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hair: 100%|██████████| 1147/1147 [00:59<00:00, 19.25it/s]\n",
      "cap: 100%|██████████| 1271/1271 [00:51<00:00, 24.64it/s]\n",
      "face: 100%|██████████| 1073/1073 [00:48<00:00, 22.16it/s]\n",
      "neck: 100%|██████████| 1122/1122 [00:51<00:00, 21.68it/s]\n",
      "coat: 100%|██████████| 1215/1215 [00:48<00:00, 24.81it/s]\n",
      "belt: 100%|██████████| 1086/1086 [00:46<00:00, 23.17it/s]\n",
      "pants: 100%|██████████| 1167/1167 [00:48<00:00, 24.18it/s]\n",
      "shoes: 100%|██████████| 1165/1165 [00:53<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeskywa499@gmail.com.jpg\n",
      "create json\n",
      "create json name : \n",
      "Response status code: 200\n",
      "Response headers: {'Content-Length': '6', 'Content-Type': 'text/plain;charset=UTF-8', 'Date': 'Sun, 11 Jun 2023 13:09:59 GMT', 'Ngrok-Trace-Id': 'a5706ade23031edd0e032eb763d82009'}\n",
      "Response body: 성공\n",
      "Could not parse response as JSON. Exception: Expecting value: line 1 column 1 (char 0)\n",
      "Image file deleted: input_image/zeskywa499@gmail.com.jpg\n",
      "New image file created: input_image/dlwjdgns30111@gmail.com.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f858456aa2af48fc802c7f4eabb73cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hair: 100%|██████████| 1147/1147 [00:14<00:00, 79.49it/s]\n",
      "cap: 100%|██████████| 1271/1271 [00:15<00:00, 83.69it/s]\n",
      "face: 100%|██████████| 1073/1073 [00:13<00:00, 82.21it/s]\n",
      "neck: 100%|██████████| 1122/1122 [00:13<00:00, 84.08it/s]\n",
      "coat: 100%|██████████| 1215/1215 [00:14<00:00, 82.67it/s]\n",
      "belt: 100%|██████████| 1086/1086 [00:13<00:00, 82.67it/s]\n",
      "pants: 100%|██████████| 1167/1167 [00:14<00:00, 83.17it/s]\n",
      "shoes: 100%|██████████| 1165/1165 [00:13<00:00, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlwjdgns30111@gmail.com.jpg\n",
      "create json\n",
      "create json name : \n",
      "Response status code: 200\n",
      "Response headers: {'Content-Length': '6', 'Content-Type': 'text/plain;charset=UTF-8', 'Date': 'Sun, 11 Jun 2023 13:21:40 GMT', 'Ngrok-Trace-Id': '5d063153928bd610f2a963fa77a094fa'}\n",
      "Response body: 성공\n",
      "Could not parse response as JSON. Exception: Expecting value: line 1 column 1 (char 0)\n",
      "Image file deleted: input_image/dlwjdgns30111@gmail.com.jpg\n",
      "New image file created: input_image/dlwjdgns30111@gmail.com.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05945f05a2984538aa1cb72aadfc434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hair: 100%|██████████| 1147/1147 [00:13<00:00, 82.42it/s]\n",
      "cap: 100%|██████████| 1271/1271 [00:15<00:00, 83.66it/s]\n",
      "face: 100%|██████████| 1073/1073 [00:12<00:00, 83.09it/s]\n",
      "neck: 100%|██████████| 1122/1122 [00:13<00:00, 82.85it/s]\n",
      "coat: 100%|██████████| 1215/1215 [00:14<00:00, 83.15it/s]\n",
      "belt: 100%|██████████| 1086/1086 [00:13<00:00, 80.37it/s]\n",
      "pants: 100%|██████████| 1167/1167 [00:14<00:00, 81.41it/s]\n",
      "shoes: 100%|██████████| 1165/1165 [00:17<00:00, 67.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlwjdgns30111@gmail.com.jpg\n",
      "create json\n",
      "create json name : \n",
      "Response status code: 200\n",
      "Response headers: {'Content-Length': '6', 'Content-Type': 'text/plain;charset=UTF-8', 'Date': 'Sun, 11 Jun 2023 13:49:12 GMT', 'Ngrok-Trace-Id': '7d614ba2dbd9101e34282eb404ff76c6'}\n",
      "Response body: 성공\n",
      "Could not parse response as JSON. Exception: Expecting value: line 1 column 1 (char 0)\n",
      "Image file deleted: input_image/dlwjdgns30111@gmail.com.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = \"input_image\"  # 이미지 파일이 생성될 경로\n",
    "    output_dir = 'result'\n",
    "    post_url = 'https://956d-125-137-22-250.ngrok-free.app/upload'\n",
    "\n",
    "    model_path = \"./output/pytorch_lora_weights.bin\"\n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16,\n",
    "        safety_checker=None,\n",
    "        feature_extractor=None,\n",
    "        requires_safety_checker=False\n",
    "    )\n",
    "\n",
    "    # load lora weights\n",
    "    pipe.unet.load_attn_procs(model_path)\n",
    "    # set to use GPU for inference\n",
    "    pipe.to(device)\n",
    "    print('load model')\n",
    "\n",
    "    event_handler = ImageHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path, recursive=False)\n",
    "    observer.start()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06fa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
